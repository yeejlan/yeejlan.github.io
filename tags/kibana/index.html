<!DOCTYPE html><html><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="alternative" href="/atom.xml" title="Yee's 部落格" type="application/atom+xml"><link rel="icon" href="/favicon.png"><title>kibana - Yee's 部落格</title><link rel="stylesheet" href="/css/main.css" type="text/css"><!--[if lt IE 9]><script>(function(a,b){a="abbr article aside audio bdi canvas data datalist details dialog figcaption figure footer header hgroup main mark meter nav output progress section summary template time video".split(" ");for(b=a.length-1;b>=0;b--)document.createElement(a[b])})()</script><![endif]--></head><body><header class="head"><h1 class="head-title u-fl"><a href="/">Yee's 部落格</a></h1><nav class="head-nav u-fr"><ul class="head-nav__list"><li class="head-nav__item"><a href="/" class="head-nav__link">Home</a></li><li class="head-nav__item"><a href="/archives" class="head-nav__link">Archives</a></li></ul></nav></header><main class="main"><article class="post"><header class="post__head"><time datetime="2014-07-15T08:09:00.000Z" class="post__time">July 15, 2014</time><h1 class="post__title"><a href="/2014/07/15/log-collection-using-logstash-elasticsearch-and-kibana/">使用logstash, elasticsearch, kibana做日志分析系统</a></h1></header><div class="post__main echo"><p>一般情况下，一个站点会由多台server构成, 每台server每天会产生多种不同的日志，为了方面分析线上日志，常用做法是把线上日志集中存储到一个地方，然后按照日期，日志类型，日志内关键字等条件查询。而logstash, elasticsearch, 和kibana就是用来做这件事的开源解决方案。</p>
<p><a href="http://logstash.net/" target="_blank" rel="external">Logstash</a> 运行于Jruby上的日志收集和分析系统，支持多种后端存储，包括elasticsearch, s3, riak, mongodb, redis等<br><a href="http://www.elasticsearch.org/" target="_blank" rel="external">Elasticsearch</a> Java写的搜索引擎，简单好用，很适合日志的存储和查询, 简称ES<br><a href="http://www.elasticsearch.org/overview/kibana/" target="_blank" rel="external">Kibana</a> Elasticsearch的查询前端，最早用PHP写的，后来用Ruby重新实现了一遍，最新版本是纯Javascript的，直接在浏览器端运行。</p>
<p>架构上，在服务器不多的情况下，可以使用Logstash分析日志后，直接存储到ES里面，然后调用Kibana做日志查询。</p>
<p>如果服务器很多，或者是需要跨网络，那么可以使用前向代理，做成树状结构，树叶是Logstash，分析完成后传给树枝<a href="https://github.com/elasticsearch/logstash-forwarder" target="_blank" rel="external">logstash-forwarder</a>, 然后传给树干Logstash, 最终输出汇总给ES</p>
<p>树枝的角色一般叫做shipper，有很多方案可以代替logstash-forwarder, 比如redis, zeromq, rabbitmq等</p>
<p>Logstash, elasticsearch, kibana的安装都很简单，这里直接略过，下面说下logstash是如何完成日志收集工作的。</p>
<p>Logstash日志收集可以分成3大块，input, filter和output, 可以通过启动时指定配置文件来配置。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre>1
</pre></td><td class="code"><pre>./bin/logstash <span class="operator">-f</span> config_file
</pre></td></tr></table></figure>

<h3 id="Input是配置日志源的，这里使用文件做例子:">Input是配置日志源的，这里使用文件做例子:</h3>
<figure class="highlight config"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
</pre></td><td class="code"><pre>input {
  file {
    #日志存储格式 /web/mywebsite/logs/<span class="number">201407</span>/login_errr_10.<span class="keyword">log</span>
    path =&gt; <span class="string">"/web/mywebsite/logs/*/*"</span>  
    <span class="keyword">type</span> =&gt; <span class="string">"web_log"</span>
  }

  file {
    #日志存储格式 /web/mywebsite/logs/apache_access.<span class="keyword">log</span>
    path =&gt; <span class="string">"/web/mywebsite/logs/*"</span>
    <span class="keyword">type</span> =&gt; <span class="string">"access_log"</span>
  }
}
</pre></td></tr></table></figure>

<p>可以看到指定输入的时候可以使用通配符监视多个文件。</p>
<h3 id="Filter用来对日志做过滤，比较常用的filter有">Filter用来对日志做过滤，比较常用的filter有</h3>
<p><a href="http://logstash.net/docs/1.4.2/filters/grok" target="_blank" rel="external">grok</a> 通过正则表达式把每一行的日志做匹配，把非结构化的信息变成结构化的<br><a href="http://logstash.net/docs/1.4.2/filters/date" target="_blank" rel="external">date</a> 可以用指定字段的值作为当前log的时间戳，而不是使用导入log时的系统时间。<br><a href="http://logstash.net/docs/1.4.2/filters/multiline" target="_blank" rel="external">multiline</a> 可以把多行日志合并成一个logstash事件</p>
<p>解释起来比较拗口，看实际的配置例子更容易理解。</p>
<p><figure class="highlight config"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
</pre></td><td class="code"><pre>filter {
  <span class="comment">#可以使用条件语句的, 中括号里面的[type]代表引用type这个字段的值</span>
  <span class="keyword">if</span> [type] == <span class="string">"access_log"</span> {
    grok {
      <span class="comment">#COMBINEDAPACHELOG, 预定义的一组正则</span>
      match =&gt; { <span class="string">"message"</span> =&gt; <span class="string">"%{COMBINEDAPACHELOG}"</span> }
    }

    <span class="comment">#这里把[timestamp]这个字段的值按照"dd/MMM/yyyy:HH:mm:ss Z"的格式解析成日期，作为本条log的产生日期。</span>
    date {
      match =&gt; [ <span class="string">"timestamp"</span> , <span class="string">"dd/MMM/yyyy:HH:mm:ss Z"</span> ]
    }
  } <span class="keyword">else</span> {

    <span class="comment">#匹配这样的消息:  2014-07-14T22:10:51-07:00 INFO (6): log body</span>
    grok {
      match =&gt; {<span class="string">"message"</span>  =&gt; <span class="string">"%{TIMESTAMP_ISO8601:timestamp} %{DATA:data}"</span>}
    }

    <span class="comment">#这里把[timestamp]这个字段的值按照iso8601的格式解析</span>
    date {
      match =&gt; [ <span class="string">"timestamp"</span> , <span class="string">"ISO8601"</span> ]
    }

    <span class="comment">#增加[site], [log]字段，比如/web/mywebsite/logs/login_error_10.log</span>
    <span class="comment">#匹配到的[site] == 'mywebsite', [log] = 'login_error_'</span>
    ruby {
        code =&gt; <span class="string">"
           site = 'null'
           log = 'null'
           m = /(.*)\/(.*)\/logs(.*)\/([a-zA-Z\-_]+)(.*)\.(.*)/.match(event['path'])
           site = m[2]; log=m[4] if m
           event['site'] = site
           event['log'] = log
        "</span>
    }
  }
}
</pre></td></tr></table></figure><br>上面的COMBINEDAPACHELOG是一组预定义的正则，<a href="https://github.com/logstash/logstash/tree/v1.4.2/patterns" target="_blank" rel="external">https://github.com/logstash/logstash/tree/v1.4.2/patterns</a>这里能看到更多的。</p>
<p>使用上面配置解析出的log如下</p>
<p><figure class="highlight config"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
</pre></td><td class="code"><pre>{
  <span class="string">"message"</span> =&gt; <span class="string">"2014-07-14T22:12:26-07:00 INFO (6): Log detail"</span>,
  <span class="string">"@version"</span> =&gt; <span class="string">"1"</span>,
  <span class="string">"@timestamp"</span> =&gt; <span class="string">"2014-07-15T05:12:26.000Z"</span>,
  <span class="string">"type"</span> =&gt; <span class="string">"web_log"</span>,
  <span class="string">"host"</span> =&gt; <span class="string">"myserver.local"</span>,
  <span class="string">"path"</span> =&gt; <span class="string">"/web/mywebsite/logs/201407/login_error_14.txt"</span>,
  <span class="string">"timestamp"</span> =&gt; <span class="string">"2014-07-14T22:12:26-07:00"</span>
  <span class="string">"site"</span> =&gt; <span class="string">"mywebsite"</span>,
  <span class="string">"log"</span> =&gt; <span class="string">"login_error_"</span>  
}
</pre></td></tr></table></figure></p>
<h2 id="在使用Filter转换好格式后，就可以配置output输出了">在使用Filter转换好格式后，就可以配置output输出了</h2>
<p><figure class="highlight config"><table><tr><td class="gutter"><pre>1
2
3
4
</pre></td><td class="code"><pre>output {
  stdout { codec =&gt; rubydebug }
  elasticsearch_http { host =&gt; localhost port =&gt; <span class="number">9200</span>}
}
</pre></td></tr></table></figure><br>可以看到，我配置了2个输出，一个使用rubydebug的格式打印到console上，一个使用elasticsearch_http输出到ES。</p>
<p>以上就是logstash的配置过程，最重点的部分在filter上。数据到了ES之后，使用kibana查询可以参考这里的<a href="http://www.elasticsearch.org/guide/en/kibana/current/" target="_blank" rel="external">介绍</a></p>
</div><footer class="post__foot u-cf"><ul class="post__tag u-fl"><li class="post__tag__item"><a href="/tags/logstash/" class="post__tag__link">logstash</a></li><li class="post__tag__item"><a href="/tags/elasticsearch/" class="post__tag__link">elasticsearch</a></li><li class="post__tag__item"><a href="/tags/kibana/" class="post__tag__link">kibana</a></li></ul><a href="/2014/07/15/log-collection-using-logstash-elasticsearch-and-kibana/#disqus_thread" class="post__foot-link u-fr">0 COMMENTS</a></footer></article></main><footer class="foot"><div class="foot-copy u-fl">&copy; 2014 Yu Fang</div><menu class="page-menu u-fr"><li class="page-menu__item"><span title="Previous" class="page-menu__link icon-arrow-left page-menu__link--disabled"></span></li><li class="page-menu__item"><span title="Next" class="page-menu__link icon-arrow-right page-menu__link--disabled"></span></li></menu></footer><script>(function(h,g,l,k,j,i){j=h.createElement(g),i=h.getElementsByTagName(g)[0],
j.src="//"+l+".disqus.com/"+k+".js",i.parentNode.insertBefore(j,i)})
(document,"script","yeesblog","count");
</script><script>var disqus_shortname = "yeesblog";
(function () {
var s = document.createElement('script'); s.async = true;
s.type = 'text/javascript';
s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
(document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
}());
</script></body></html>